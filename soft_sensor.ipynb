{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import  Bidirectional,Dense, Dropout, Activation, Flatten, LSTM, TimeDistributed, RepeatVector\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error,r2_score\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# prepare training data and data visualization\n",
    "\n",
    "def readdata(datapath):\n",
    "    \"\"\"read data with datetime index\n",
    "    Args:\n",
    "       datapath(str):csv file\n",
    "    Returns:\n",
    "       rawdata(dataframe)\n",
    "    \"\"\"\n",
    "    rawdata=pd.read_csv(datapath)\n",
    "    rawdata['time'] = pd.to_datetime(rawdata['Time'],format=\"%Y/%m/%d %H:%M\")\n",
    "    rawdata['time']=rawdata['time'].apply(pd.Timestamp)\n",
    "    rawdata.index=rawdata['time']\n",
    "    rawdata=rawdata.drop(['Time','time'], axis=1)\n",
    "    return rawdata\n",
    "\n",
    "def data_norm(df):\n",
    "    \"\"\"data normalization(min_max)\n",
    "    Args:\n",
    "       df(dataframe)\n",
    "    Returns:\n",
    "       df_norm(dataframe)\n",
    "    \"\"\"\n",
    "    column_high= {\n",
    "                'X1':3.5,\n",
    "                'X2':13\n",
    "                }\n",
    "    column_low= {\n",
    "                'X1':2.6,\n",
    "                'X2':-0.2,\n",
    "                }\n",
    "    \n",
    "    df_norm=pd.DataFrame()\n",
    "    for i in df:    \n",
    "        df_norm[i]=(df[i]-column_low[i])/(column_high[i]-column_low[i])\n",
    "    return df_norm\n",
    "\n",
    "def up_low_check(df):\n",
    "    \"\"\"Check the upper and lowwer bonds and drop the outlier\n",
    "    Args:\n",
    "       Dataframe\n",
    "    Returns:\n",
    "       Dataframe\n",
    "    \"\"\"\n",
    "    for i in df.columns:\n",
    "        mask1=df[i]>column_high[i]\n",
    "        mask2=df[i]<column_low[i]\n",
    "        df.loc[(mask1) | (mask2),:]=np.nan\n",
    "    return df\n",
    "\n",
    "def buildWindows(df, windowsize,feature):\n",
    "    \"\"\"Build data scrolling in the data window \n",
    "    Args:\n",
    "       df(dataframe):Features and targets\n",
    "       windowsize(int):Window sizes\n",
    "       feature(int): Number of features\n",
    "    Returns:\n",
    "       numpy: X ,Y\n",
    "    \"\"\"\n",
    "    X_Window, Y_Window = [], []\n",
    "    for i in range(df.shape[0]-windowsize+1):\n",
    "        df_select=df.iloc[i:i+windowsize,0:feature:].drop_duplicates()\n",
    "        if df_select.shape[0]==df.iloc[i:i+windowsize,0:feature:].shape[0]:\n",
    "            Y_Window.append(np.array(df.iloc[i+past:i+windowsize,feature:]))\n",
    "            X_Window.append(np.array(df.iloc[i:i+windowsize,0:feature])) \n",
    "    Y_Window=np.array(Y_Window).reshape(-1,1)\n",
    "    return np.array(X_Window), np.array(Y_Window)\n",
    "\n",
    "def splitData(X,Y,val_size,mode):\n",
    "    \"\"\"Train/Validation data split \n",
    "    Args:\n",
    "       X(numpy):features\n",
    "       Y(numpy):targets\n",
    "       val_size(float): validation sizes(ratio)\n",
    "    Returns:\n",
    "       numpy: X_train, Y_train, X_val, Y_val\n",
    "    \"\"\"\n",
    "    if mode==\"random\":\n",
    "        from sklearn.model_selection import train_test_split\n",
    "        X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=val_size, random_state=42)\n",
    "    if mode==\"normal\":\n",
    "        X_train = X[:int(X.shape[0]*(1-val_size))]\n",
    "        Y_train = Y[:int(Y.shape[0]*(1-val_size))]\n",
    "        X_val = X[int(X.shape[0]*(1-val_size)):]\n",
    "        Y_val = Y[int(Y.shape[0]*(1-val_size)):]\n",
    "    return X_train, Y_train, X_val, Y_val\n",
    "\n",
    "def training_set_prepare(datapath,y_num,featureNum,WindowsSize,futureDay):\n",
    "    \"\"\"training_set_prepare\n",
    "    Args:\n",
    "       datapath(str):\n",
    "       y_num(int): Number of targets\n",
    "       featureNum(int): Number of features\n",
    "       \n",
    "    Returns:\n",
    "       numpy: X_train, Y_train, X_val, Y_val\n",
    "    \"\"\"\n",
    "    \n",
    "    training_data=readdata(datapath)\n",
    "    new_training_set_describe=training_data.describe().T\n",
    "    new_up_low(new_training_set_describe)\n",
    "    training_data_up_low_check=up_low_check(training_data)\n",
    "    training_set_norm=data_norm(training_data_up_low_check)\n",
    "    training_set_norm[\"Y_+1\"]=training_set_norm[\"Y\"].shift(-1)\n",
    "\n",
    "    X_train_W, Y_train_W = buildWindows(training_set_norm, WindowsSize,featureNum)\n",
    "    X_train, Y_train, X_val, Y_val = splitData(X_train_W, Y_train_W, 0.2)\n",
    "    return X_train, Y_train, X_val, Y_val\n",
    "\n",
    "def data_plot(rawdata):\n",
    "    \"\"\"plot the data in time series\n",
    "    Args:\n",
    "       rawdata(dataframe):   \n",
    "    Returns:\n",
    "       None\n",
    "    \"\"\"\n",
    "    column_name=rawdata.columns\n",
    "    column_num=len(column_name)\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure(figsize=(50,column_num*10)).patch.set_facecolor('white')\n",
    "    data_P=rawdata\n",
    "    for idx, i in enumerate(column_name):\n",
    "        plt.subplot(column_num,1,idx+1)\n",
    "        plt.title(i,fontsize=50)\n",
    "        plt.scatter(rawdata.index,rawdata[i],s=5,c=\"#56B4E9\")\n",
    "        plt.yticks(fontsize=40)\n",
    "        plt.xticks(fontsize=40,rotation=45)\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "#soft sensor \n",
    "def buildLSTMModel(X_shape,Y_shape):\n",
    "    \"\"\"Build LSTM model  \n",
    "    Args:\n",
    "       X_shape(numpy)\n",
    "       Y_shape(numpy)\n",
    "    Returns:\n",
    "       model(keras model)\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units = 64, activation='tanh',recurrent_initializer='orthogonal',\n",
    "                   return_sequences = True, input_length=X_shape[1], input_dim=X_shape[2]))\n",
    "    model.add(LSTM(units = 32,activation='tanh'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(units=Y_shape, activation=\"linear\", name=\"output\"))\n",
    "    model.compile(loss=\"mse\", optimizer=\"adam\",metrics=['mse'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "def show_train_history(train_history,model_name):\n",
    "    \"\"\"plot training report   \n",
    "    Args:\n",
    "       train_history(training history)\n",
    "       model_name(str)\n",
    "    Returns:\n",
    "       None\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(8,5))\n",
    "    plt.plot(train_history.history['mean_squared_error'], label='train')\n",
    "    plt.plot(train_history.history['val_mean_squared_error'], label='validation')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MSE(Loss)')\n",
    "    plt.title('Training Report--{}'.format(model_name),fontsize=15)\n",
    "    plt.text(1,0.00026,\"train_loss:{}  val_loss:{}\".format(round(train_history.history['mean_squared_error'][-1], 5),\n",
    "                                                 round(train_history.history['val_mean_squared_error'][-1], 5)))\n",
    "    plt.legend()\n",
    "    plt.savefig('Training Report--{}.jpg'.format(model_name))\n",
    "    plt.show()\n",
    "    \n",
    "def soft_sensor_train(X_train, Y_train, X_val, Y_val,modle_name):\n",
    "    model = buildLSTMModel(X_train.shape,Y_train.shape[1])\n",
    "    callback = EarlyStopping(monitor=\"val_loss\", patience=5, verbose=1, mode=\"auto\")\n",
    "    reduce_lr = ReduceLROnPlateau(factor=0.2, \n",
    "                                  min_lr=1e-12, \n",
    "                                  monitor='val_loss', \n",
    "                                  patience=10,\n",
    "                                  verbose=1)\n",
    "    history=model.fit(X_train, Y_train_rs, epochs=50, batch_size=100, validation_data=(X_val, Y_val), callbacks=[callback,reduce_lr])\n",
    "    model.save(\"{}_.h5\".format(modle_name))\n",
    "    show_train_history(history,\"{}\".format(modle_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-gpu)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
